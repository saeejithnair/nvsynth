{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import re\n",
    "import json\n",
    "from PIL import Image\n",
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os.path as osp\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "\n",
    "data_root = pathlib.Path('/pub2/data/aging/')\n",
    "img_dir = '2D_Image'\n",
    "ann_dir = 'masks'\n",
    "meta_dir = 'metadata'\n",
    "remapped_dir = data_root.joinpath('remapped_masks')\n",
    "if remapped_dir.exists():\n",
    "    shutil.rmtree(remapped_dir)\n",
    "remapped_dir.mkdir()\n",
    "\n",
    "np.random.seed(1)\n",
    "metadata_reader = pd.read_csv(\"./aging_individual_item_metadata.csv\")\n",
    "\n",
    "FOOD_CLASSES = metadata_reader.food_item_type.unique().tolist()\n",
    "PALETTE = np.c_[np.random.choice(range(256), size=(len(FOOD_CLASSES),3), replace=False), 255 + np.zeros(len(FOOD_CLASSES)).astype(int)].tolist()\n",
    "\n",
    "IMAGE_PATH = data_root.joinpath(img_dir)\n",
    "ANN_PATH = data_root.joinpath(ann_dir)\n",
    "META_PATH = data_root.joinpath(meta_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('(140, 255, 25, 255)', dtype='<U19')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array('(140, 255, 25, 255)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[140, 255,  25]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([int(s) for s in re.findall(r'\\d+', '(140, 255, 25, 255)')[:-1]]).reshape(1,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [06:17<00:00, 12.60s/it]\n"
     ]
    }
   ],
   "source": [
    "img_sub_dirs = [x for x in IMAGE_PATH.iterdir()]\n",
    "for img_sub_dir in tqdm(img_sub_dirs):\n",
    "    if not img_sub_dir.is_dir():\n",
    "        continue\n",
    "    # Check scene exists under all circumstances\n",
    "    scene_dir = img_sub_dir.name\n",
    "    meta_sub_dir = META_PATH.joinpath(scene_dir)\n",
    "    ann_sub_dir = ANN_PATH.joinpath(scene_dir)\n",
    "    if not (meta_sub_dir.exists() and ann_sub_dir.exists()):\n",
    "        print(f\"Warning: {scene_dir} not exists\")\n",
    "        continue\n",
    "    \n",
    "    scene_destination = remapped_dir.joinpath(scene_dir)\n",
    "    if not scene_destination.exists():\n",
    "        scene_destination.mkdir()\n",
    "    # Get files in advance to avoid iterate on newly generated files since we will save files as we walk through\n",
    "    imgs = [x for x in sorted(img_sub_dir.iterdir())]\n",
    "    anns = [x for x in sorted(ann_sub_dir.iterdir()) if not str(x).endswith('remapped.png')]\n",
    "    metas = [x for x in sorted(meta_sub_dir.iterdir())]\n",
    "    for img_file, anno_file, meta_file in zip(imgs, anns, metas):\n",
    "        # CHECK IF THE SAME FILE\n",
    "        # pattern_check = \"[0-9]+_viewport_[0-9]+\"\n",
    "        # im_re, an_re, me_re = re.search(pattern_check, str(img_file.name)), re.search(pattern_check, str(anno_file.name)), re.search(pattern_check, str(meta_file.name))\n",
    "        # if not (im_re and an_re and me_re):\n",
    "        #     raise ValueError(\"NOT FOUND\")\n",
    "        # if im_re.group() != an_re.group() and im_re.group() != me_re.group():\n",
    "        #     raise ValueError(\"NOT FOUND\")\n",
    "        if img_file.name != anno_file.name and img_file.name != meta_file.name:\n",
    "            raise ValueError(\"NOT FOUND\")\n",
    "\n",
    "        # Parse mask, retrieve classes and local palette\n",
    "        metadata_dict = None\n",
    "        with open(meta_file) as f:\n",
    "            metadata_dict = json.load(f)\n",
    "        mask_remap = {}\n",
    "        for rgb, class_obj in metadata_dict.items():\n",
    "            cls_name = class_obj['class']\n",
    "            if cls_name != 'food' and cls_name not in FOOD_CLASSES:\n",
    "                FOOD_CLASSES.append(cls_name)\n",
    "                # Generate a new unique palette\n",
    "                while True:\n",
    "                    new_color = np.r_[np.random.choice(range(256), size=3), 255].tolist()\n",
    "                    if new_color not in PALETTE:\n",
    "                        PALETTE.append(new_color)\n",
    "                        break\n",
    "            elif cls_name == 'food':\n",
    "                cls_name = metadata_reader.loc[metadata_reader['file_name'] == class_obj['food_type'].replace('_','-')].food_item_type.to_list()[0]\n",
    "            mask_remap[FOOD_CLASSES.index(cls_name)] = [int(s) for s in re.findall(r'\\d+', rgb)]\n",
    "        # print(anno_file)\n",
    "\n",
    "        # Remap the pixels into our palette\n",
    "        img = np.array(Image.open(anno_file), dtype=np.uint8)\n",
    "        seg_map_2d = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
    "        test = [tuple(e) for c in img for e in c]\n",
    "        # print(test)\n",
    "        # print(\"UNIQUE IMAGE PIXEL\", set(test))\n",
    "        for index, color in mask_remap.items():\n",
    "            m = np.all(img == np.array(color).reshape(1,1,4), axis=2)\n",
    "            seg_map_2d[m] = index\n",
    "        # img.save(\"test.png\")\n",
    "        # print(np.unique(seg_map_2d))\n",
    "        # np.savetxt('test.txt', seg_map_2d, '%d')\n",
    "        seg_img = Image.fromarray(seg_map_2d).convert('P')\n",
    "        seg_img.putpalette(np.array(PALETTE, dtype=np.uint8))\n",
    "        seg_file_name = remapped_dir.joinpath(scene_dir).joinpath(anno_file.name)\n",
    "        seg_img.save(seg_file_name)\n",
    "        # img_arr = np.array(img)\n",
    "        # img_arr = np.array([[PALETTE[mask_remap['('+ ', '.join(pix.astype(str)) +')']] for pix in row] for row in img_arr]).astype(np.uint8)\n",
    "        # Image.fromarray(img_arr).save(remapped_dir.joinpath(scene_dir).joinpath(anno_file.name))\n",
    "        # im = plt.imshow(img_arr)\n",
    "        # plt.show()\n",
    "        # break\n",
    "    # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array(PALETTE).shape == np.unique(np.array(PALETTE), axis=0).shape\n",
    "\n",
    "PALETTE_DICT = {\n",
    "    class_name: color for color, class_name in zip(PALETTE, FOOD_CLASSES)\n",
    "}\n",
    "# print(PALETTE_DICT)\n",
    "# Serializing json\n",
    "json_object = json.dumps(PALETTE_DICT, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"palette_remapped.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb9a137472cefbebd6bd9707f4bd79e7e186f7f446125340f1b4752615b39064"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
